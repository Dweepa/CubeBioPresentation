{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "presentation- research credits",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVVNIu23kHUH",
        "colab_type": "code",
        "outputId": "cf920a88-bd0a-4b13-dc3b-b69a9a48103d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ8vDcMbkbEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "!pip3 install --quiet seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd58Olnwr2kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@pa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoPgnPVasJhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import scipy.spatial as sp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKb-Ot7cr5PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed = hub.Module(module_url)\n",
        "\n",
        "# Compute a representation for each message, showing various lengths supported.\n",
        "sentence1 = \"The name I have is dweepa\"\n",
        "sentence2 = \"my name is dweepa\"\n",
        "messages = [sentence1, sentence2]\n",
        "\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojev2hv7xa3k",
        "colab_type": "text"
      },
      "source": [
        "# Google Embedding with Similarity Measure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J0A95sMxILZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def google_embedding(messages):\n",
        "    with tf.Session() as session:\n",
        "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "        message_embeddings = session.run(embed(messages))\n",
        "        me = np.array(message_embeddings).tolist()\n",
        "        return 1 - sp.distance.cosine(me[0], me[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8D--CXFr9my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "messages = [['What are natural numbers?', 'Which is the least natural number?'],\n",
        "            [\"Should I learn Java or Python first?\", \"If I had to choose between learning Java or Python, which should I opt to learn first?\"],\n",
        "            ['Which are the most popular pizzas ordered at Domino’s?', 'How many calories do the most popular Domina’s pizzas contain?'],\n",
        "            ['How do you start a bakery?', 'What must I do to start a bakery business?']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8fYNcKRxKMx",
        "colab_type": "code",
        "outputId": "50c4d715-e4da-43de-8f46-67be55785e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "list(map(google_embedding, messages))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7986731168459479,\n",
              " 0.9439757577616475,\n",
              " 0.7049273669173751,\n",
              " 0.8648544846558146]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNAXAf2x9JZF",
        "colab_type": "text"
      },
      "source": [
        "# Synset approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQRIIIJuN9gP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXV8_nHnMCTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(sentence):\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from nltk.corpus import stopwords\n",
        "    import nltk\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "    \n",
        "    tokenized_word=word_tokenize(sentence)\n",
        "    sentence = [word.lower() for word in tokenized_word if word.isalpha()]\n",
        "    stop_words=set(stopwords.words(\"english\"))\n",
        "    filtered=[]\n",
        "    for w in sentence:\n",
        "        if w not in stop_words:\n",
        "            filtered.append(w)\n",
        "    pos = nltk.pos_tag(filtered)\n",
        "    return pos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIaWPlD7MNcM",
        "colab_type": "text"
      },
      "source": [
        "## Find Similarity Matrix for each algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE3ekaDPMFs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_similarity_matrix(syns, method):\n",
        "    sim_matrix = []\n",
        "    for key in syns.keys():\n",
        "        synlist = syns[key]\n",
        "        similarities = []\n",
        "        for key1 in syns.keys():  \n",
        "            maxsim = 0\n",
        "            if method == 'wp' or method == 'lch':\n",
        "                for i in synlist:\n",
        "                    synlist1 = syns[key1]\n",
        "                    for j in synlist1:\n",
        "                        if(method == 'wp'):\n",
        "                            sim = i.wup_similarity(j)\n",
        "                        if(method == 'lch'):\n",
        "                            try:\n",
        "                                sim = i.lch_similarity(j)\n",
        "                            except:\n",
        "                                continue\n",
        "                        if(str(sim) == 'None'):\n",
        "                            sim=0\n",
        "                        if(sim>maxsim):\n",
        "                            maxsim=sim\n",
        "            else:\n",
        "                from nltk.corpus import wordnet as wn\n",
        "                from itertools import product \n",
        "                if key[1] == key1[1]:\n",
        "                    if(method == 'res'):\n",
        "                        from nltk.corpus import wordnet_ic\n",
        "                        brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
        "                        sim = max([(wn.res_similarity(s1, s2, brown_ic) if(s1.pos() == s2.pos() and s1.pos()!='a' and s2.pos()!='a' and s1.pos()!='s' and s2.pos!='s') else 0,s1,s2) for s1, s2 in product(syns[key], syns[key1]) ])\n",
        "                        maxsim=sim[0]\n",
        "                                        \n",
        "                    if(method == 'jcn'):\n",
        "                        from nltk.corpus import wordnet_ic\n",
        "                        brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
        "                        sim = max([(wn.jcn_similarity(s1, s2, brown_ic) if(s1.pos() == s2.pos() and s1.pos()!='a' and s2.pos()!='a' and s1.pos()!='s' and s2.pos!='s') else 0,s1,s2) for s1, s2 in product(syns[key], syns[key1]) ])\n",
        "                        maxsim=sim[0]\n",
        "                else:\n",
        "                    maxsim = 0\n",
        "            similarities.append(maxsim)\n",
        "        sim_matrix.append(similarities)\n",
        "    return sim_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFAARsPOMY7L",
        "colab_type": "text"
      },
      "source": [
        "### Function to create 2D matrix in double dictionary form and function to convert matrix to data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-V02F_0MFv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_vector(sent, corpus, dicti):\n",
        "    vector = []\n",
        "    for word in corpus:\n",
        "        if word in sent:\n",
        "            vector.append(1)\n",
        "        else:\n",
        "            maxval = 0\n",
        "            for word1 in corpus:\n",
        "                if word==word1:\n",
        "                    continue\n",
        "                if dicti[word][word1]>maxval:\n",
        "                    maxval = dicti[word][word1]\n",
        "                    bestword = word1\n",
        "            if(maxval<0.4):\n",
        "                vector.append(0)\n",
        "            else:\n",
        "                vector.append(maxval)\n",
        "    return vector\n",
        "                \n",
        "            \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVYp1yeJMFyU",
        "colab_type": "code",
        "outputId": "5bac2dc1-7ce9-44eb-d92b-f89b6a0b6387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "sent1 = \"I like fish fry with lunch whenever I am by the side of sea.\"\n",
        "sent2 = \"Our professor is ferocious i.e. if you make noise in classroom, he will fry you in front of everybody.\"\n",
        "pre_sent1 = preprocess(sent1)\n",
        "pre_sent2 = preprocess(sent2)\n",
        "print(pre_sent1)\n",
        "print(pre_sent2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[('like', 'IN'), ('fish', 'JJ'), ('fry', 'NN'), ('lunch', 'NN'), ('whenever', 'WRB'), ('side', 'NN'), ('sea', 'NN')]\n",
            "[('professor', 'NN'), ('ferocious', 'JJ'), ('make', 'VBP'), ('noise', 'JJ'), ('classroom', 'NN'), ('fry', 'NN'), ('front', 'NN'), ('everybody', 'NN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHJkZYw7MhfP",
        "colab_type": "code",
        "outputId": "fdb4621c-f9d9-4906-ebfa-571fffb77b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('wordnet_ic')\n",
        "content_words = []\n",
        "content_words.extend(pre_sent1+pre_sent2)\n",
        "content_words = set(content_words)\n",
        "corpus = []\n",
        "corpus_words=[]\n",
        "syns ={}\n",
        "for syn in content_words:\n",
        "    if len(wordnet.synsets(syn[0])) == 0:\n",
        "           continue\n",
        "    syns[syn] = wordnet.synsets(syn[0])\n",
        "    corpus.append(syn)\n",
        "    corpus_words.append(syn[0])\n",
        "sim_matrix_wp = find_similarity_matrix(syns, 'wp')\n",
        "sim_matrix_res = find_similarity_matrix(syns, 'res')\n",
        "sim_matrix_jcn = find_similarity_matrix(syns, 'jcn')\n",
        "sim_matrix_lch = find_similarity_matrix(syns, 'lch')\n",
        "\n",
        "\n",
        "wp_dict = convert_to_doubledict(sim_matrix_wp, corpus_words)\n",
        "res_dict = convert_to_doubledict(sim_matrix_res, corpus_words)\n",
        "jcn_dict = convert_to_doubledict(sim_matrix_jcn, corpus_words)\n",
        "lch_dict = convert_to_doubledict(sim_matrix_lch, corpus_words)\n",
        "\n",
        "wp_df = convert_to_df(sim_matrix_wp, corpus_words)\n",
        "res_df = convert_to_df(sim_matrix_res, corpus_words)\n",
        "jcn_df = convert_to_df(sim_matrix_jcn, corpus_words)\n",
        "lch_df = convert_to_df(sim_matrix_lch, corpus_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PftsYyI-O8xC",
        "colab_type": "code",
        "outputId": "0399af59-a848-4684-f3a0-34db760038ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print(\"Similarity matrix for Wu Palmer: \\n\")\n",
        "print(wp_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity matrix for Wu Palmer: \n",
            "\n",
            "              front      make      like  ...       fry  ferocious     noise\n",
            "front      1.000000  0.555556  0.555556  ...  0.600000   0.333333  0.444444\n",
            "make       0.555556  1.000000  0.900000  ...  0.400000   0.500000  0.400000\n",
            "like       0.555556  0.900000  1.000000  ...  0.400000   0.500000  0.400000\n",
            "professor  0.521739  0.105263  0.105263  ...  0.571429   0.000000  0.133333\n",
            "fish       0.631579  0.400000  0.400000  ...  0.705882   0.400000  0.285714\n",
            "side       0.947368  0.666667  0.666667  ...  0.500000   0.250000  0.588235\n",
            "classroom  0.588235  0.105263  0.105263  ...  0.444444   0.000000  0.133333\n",
            "sea        0.400000  0.250000  0.250000  ...  0.363636   0.000000  0.333333\n",
            "lunch      0.333333  0.333333  0.333333  ...  0.285714   0.333333  0.250000\n",
            "fry        0.600000  0.400000  0.400000  ...  1.000000   0.400000  0.285714\n",
            "ferocious  0.000000  0.000000  0.000000  ...  0.000000   1.000000  0.000000\n",
            "noise      0.444444  0.400000  0.400000  ...  0.285714   0.333333  1.000000\n",
            "\n",
            "[12 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAjD7afYO__x",
        "colab_type": "code",
        "outputId": "54ae5e08-ee12-4ce4-e1f0-aa9bce374599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "print(\"Similarity matrix for Resnik: \")\n",
        "print(res_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity matrix for Resnik: \n",
            "              front      make       like  ...        fry  ferocious      noise\n",
            "front      9.821209  0.000000   0.000000  ...   2.333545          0   0.000000\n",
            "make       0.000000  7.751429   0.000000  ...   0.000000          0   0.000000\n",
            "like       0.000000  0.000000  11.469868  ...   0.000000          0   0.000000\n",
            "professor  2.333545  0.000000   0.000000  ...   6.394069          0   0.000000\n",
            "fish       0.000000  0.000000   0.000000  ...   0.000000          0  -0.000000\n",
            "side       6.825477  0.000000   0.000000  ...   1.531834          0   0.000000\n",
            "classroom  2.305849  0.000000   0.000000  ...   1.531834          0   0.000000\n",
            "sea        4.088771  0.000000   0.000000  ...   0.801759          0   0.000000\n",
            "lunch      0.801759  0.000000   0.000000  ...   0.801759          0   0.000000\n",
            "fry        2.333545  0.000000   0.000000  ...  13.772453          0   0.000000\n",
            "ferocious  0.000000  0.000000   0.000000  ...   0.000000          0   0.000000\n",
            "noise      0.000000  0.000000   0.000000  ...   0.000000          0  10.752028\n",
            "\n",
            "[12 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O2AVOk6PACu",
        "colab_type": "code",
        "outputId": "f08abd2b-902e-4438-b443-18130dd915f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "print(\"Similarity matrix for JCN: \")\n",
        "print(jcn_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity matrix for JCN: \n",
            "                   front           make  ...  ferocious          noise\n",
            "front      1.000000e+300   0.000000e+00  ...          0   0.000000e+00\n",
            "make        0.000000e+00  1.000000e+300  ...          0   0.000000e+00\n",
            "like        0.000000e+00   0.000000e+00  ...          0   0.000000e+00\n",
            "professor   6.718101e-02   0.000000e+00  ...          0   0.000000e+00\n",
            "fish        0.000000e+00   0.000000e+00  ...          0   6.305875e-02\n",
            "side        7.620869e-01   0.000000e+00  ...          0   0.000000e+00\n",
            "classroom   6.951639e-02   0.000000e+00  ...          0   0.000000e+00\n",
            "sea         8.660314e-02   0.000000e+00  ...          0   0.000000e+00\n",
            "lunch       6.025995e-02   0.000000e+00  ...          0   0.000000e+00\n",
            "fry         8.022412e-02   0.000000e+00  ...          0   0.000000e+00\n",
            "ferocious   0.000000e+00   0.000000e+00  ...          0   0.000000e+00\n",
            "noise       0.000000e+00   0.000000e+00  ...          0  1.000000e+300\n",
            "\n",
            "[12 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFEmySR4PFlO",
        "colab_type": "code",
        "outputId": "c7173c37-6c90-4b16-f7ed-e5d0bd7852c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "print(\"Similarity matrix for LCH Similarity: \")\n",
        "print(lch_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity matrix for LCH Similarity: \n",
            "              front      make      like  ...       fry  ferocious     noise\n",
            "front      3.637586  1.648659  1.648659  ...  1.691676          0  1.558145\n",
            "make       1.648659  3.637586  2.538974  ...  1.871802          0  1.648659\n",
            "like       1.648659  2.538974  3.637586  ...  1.871802          0  1.648659\n",
            "professor  1.335001  0.747214  0.747214  ...  1.691676          0  0.998529\n",
            "fish       1.845827  1.871802  1.871802  ...  2.251292          0  1.466337\n",
            "side       2.944439  1.558145  1.558145  ...  1.558145          0  1.558145\n",
            "classroom  1.558145  0.747214  0.747214  ...  1.239691          0  0.998529\n",
            "sea        1.558145  1.072637  1.072637  ...  1.558145          0  1.440362\n",
            "lunch      1.312186  1.648659  1.648659  ...  1.466337          0  1.312186\n",
            "fry        1.691676  1.871802  1.871802  ...  3.637586          0  1.466337\n",
            "ferocious  0.000000  0.000000  0.000000  ...  0.000000          0  0.000000\n",
            "noise      1.558145  1.648659  1.648659  ...  1.466337          0  3.637586\n",
            "\n",
            "[12 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF537iNmPKyj",
        "colab_type": "text"
      },
      "source": [
        "## Function to create vector for each sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYzGm9fePURU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_vector(sent, corpus, dicti):\n",
        "    vector = []\n",
        "    for word in corpus:\n",
        "        if word in sent:\n",
        "            vector.append(1)\n",
        "        else:\n",
        "            maxval = 0\n",
        "            for word1 in corpus:\n",
        "                if word == word1:\n",
        "                    continue\n",
        "                if dicti[word][word1]>maxval:\n",
        "                    maxval = dicti[word][word1]\n",
        "                    bestword = word1\n",
        "            if(maxval<0.4):\n",
        "                vector.append(0)\n",
        "            else:\n",
        "                vector.append(maxval)\n",
        "    return vector\n",
        "                \n",
        "            \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtR0O3brPUZU",
        "colab_type": "code",
        "outputId": "8614f529-6bf1-4c8b-b3ff-f8ffc79a9431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sent1_words = [i[0] for i in pre_sent1]\n",
        "sent2_words = [i[0] for i in pre_sent2]\n",
        "sent_vec1 = create_vector(sent1_words, corpus_words, lch_dict)\n",
        "sent_vec2 = create_vector(sent2_words, corpus_words, lch_dict)\n",
        "print(sent1_words)\n",
        "print(sent_vec1)\n",
        "print(sent2_words)\n",
        "print(sent_vec2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['like', 'fish', 'fry', 'lunch', 'whenever', 'side', 'sea']\n",
            "[2.9444389791664407, 2.538973871058276, 1, 1.6916760106710724, 1, 1, 1.6916760106710724, 1, 1, 1, 0, 1.6486586255873816]\n",
            "['professor', 'ferocious', 'make', 'noise', 'classroom', 'fry', 'front', 'everybody']\n",
            "[1, 1, 2.538973871058276, 1, 2.2512917986064953, 2.9444389791664407, 1, 1.6916760106710724, 1.6486586255873816, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-PigGqwP6qb",
        "colab_type": "text"
      },
      "source": [
        "Find cosine distance between the sentence vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqWZ6sGSPUc8",
        "colab_type": "code",
        "outputId": "0a7b2b51-b8bb-423b-a8b8-30c2caf43b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from scipy import spatial\n",
        "\n",
        "result = 1 - spatial.distance.cosine(sent_vec1, sent_vec2)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7259211249754025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crPxj0Q89qy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}